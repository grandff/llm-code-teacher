version: '3.9'

services:
  fastapi:
    build:
      context: ./fastapi
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - ./fastapi/app/.env
    networks:
      - app_network
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
    depends_on:
      - ollama      
      - redis
      - celery
  
  redis:
    image: "redis:alpine"
    networks:
      - app_network

  celery:
    build:
      context: ./fastapi
      dockerfile: Dockerfile
    command: celery -A app.celery_app worker --loglevel=info
    volumes:
      - ./fastapi:/app
    env_file:
      - ./fastapi/app/.env
    depends_on:
      - redis
    networks:
      - app_network

  nginx:
    build:
      context: ./nginx
      dockerfile: Dockerfile
    ports:
      - "80:80"      
    depends_on:
      - fastapi
    networks:
      - app_network
      - shared_network

  ollama:
    image: ollama/ollama:latest    
    environment:
      - API_KEY=your_ollama_api_key  # Replace or set in a safer way        
    command: ["serve"]
    networks:
      - app_network    
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
    #   interval: 60s
    #   timeout: 30s
    #   retries: 20

  
  # run-script:
  #   image: busybox
  #   networks:
  #     - app_network
  #   depends_on:
  #     ollama:
  #       condition: service_healthy
  #   entrypoint: ["/bin/sh", "-c", "exec /bin/bash -c 'ollama run llama3'"]

networks:
  app_network:
    driver: bridge
  shared_network:
    external: true